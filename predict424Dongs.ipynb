{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dong.csv', delimiter=',', encoding='euc-kr')\n",
    "# Select the required columns\n",
    "df = df[['기준일ID', '시간대구분', '총생활인구수', '행정동코드']]\n",
    "\n",
    "# Rename the columns for easier understanding\n",
    "df.rename(columns={\n",
    "    '기준일ID': 'date',\n",
    "    '시간대구분': 'hour',\n",
    "    '총생활인구수': 'total_population',\n",
    "    '행정동코드': 'dong_code'\n",
    "}, inplace=True)\n",
    "# Convert 'dong_code' to string type\n",
    "df['dong_code'] = df['dong_code'].astype(str)\n",
    "dong_codes = df['dong_code'].unique()\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_dong_codes = pd.DataFrame(dong_codes, columns=['dong_code'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_dong_codes.to_csv('dong_codes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Iterate over each 'dong' code\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m dong_code \u001b[39min\u001b[39;00m dong_codes:\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Load the trained model for the current 'dong'\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     model \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mjoblib/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdong_code\u001b[39m}\u001b[39;49;00m\u001b[39m.joblib\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m     \u001b[39m# Create a list to store the predictions for the current 'dong'\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     predictions \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Jungha Cho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_dong_codes = pd.read_csv('dong_codes.csv')\n",
    "\n",
    "# Convert the DataFrame to a list\n",
    "dong_codes = df_dong_codes['dong_code'].tolist()\n",
    "\n",
    "# Get the feature names from the training data\n",
    "feature_names = ['date','DayOfWeek_Friday', 'DayOfWeek_Monday', 'DayOfWeek_Saturday', 'DayOfWeek_Sunday', 'DayOfWeek_Thursday', 'DayOfWeek_Tuesday', 'DayOfWeek_Wednesday', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'IsWeekend']\n",
    "# Get the unique 'dong' codes\n",
    "\n",
    "current_date = pd.to_datetime(time.time(), unit='s')\n",
    "current_date = current_date.tz_localize('UTC').tz_convert('Asia/Seoul')\n",
    "current_hour = current_date.hour\n",
    "# Create a list to store the predictions for each 'dong'\n",
    "all_predictions = []\n",
    "predicted_hours = 72\n",
    "# Iterate over each 'dong' code\n",
    "for dong_code in dong_codes:\n",
    "    # Load the trained model for the current 'dong'\n",
    "    model = load(f'joblib/{dong_code}.joblib')\n",
    "\n",
    "    # Create a list to store the predictions for the current 'dong'\n",
    "    predictions = []\n",
    "\n",
    "    # Create new data points for the next x hours\n",
    "    for i in range(predicted_hours):\n",
    "        new_data = pd.Series(0, index=feature_names)  # Initialize with zeros instead of NaNs\n",
    "        new_data['date'] = (current_date + pd.DateOffset(hours=i)).strftime('%Y%m%d')\n",
    "        \n",
    "        # Set all hour features to 0\n",
    "        for h in range(24):  # Change this to 24\n",
    "            new_data['hour_' + str(h)] = 0\n",
    "        new_data['hour_' + str((current_hour + i) % 24)] = 1  # Change this to 24\n",
    "\n",
    "        # Set all DayOfWeek features to 0\n",
    "        for dow in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "            new_data['DayOfWeek_' + dow] = 0\n",
    "\n",
    "        # Determine the day of the week\n",
    "        day_of_week = (current_date + pd.DateOffset(hours=i)).day_name()\n",
    "        new_data['DayOfWeek_' + day_of_week] = 1\n",
    "\n",
    "        # Determine whether it's a weekend\n",
    "        new_data['IsWeekend'] = 1 if day_of_week in ['Saturday', 'Sunday'] else 0\n",
    "\n",
    "        # Convert the Series to a DataFrame\n",
    "        new_data_df = new_data.to_frame().transpose()\n",
    "\n",
    "        # Make a prediction for the new data point\n",
    "        new_pred = model.predict(new_data_df)\n",
    "        predictions.append(new_pred)\n",
    "\n",
    "    # Add the predictions for the current 'dong' to the overall predictions list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "print(f\"Predicted population for the next {predicted_hours} hours for each 'dong': {len(all_predictions)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
